{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit learn cheat sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cheat sheet to scikit learn. Includes\n",
    "\n",
    "- Pre-processing data\n",
    "- Models for classification\n",
    "- Models for regression (incomplete)\n",
    "- Pipelines\n",
    "\n",
    "Sources:\n",
    " - Lecture slides, Uni Michgigan Applied Data Science with Python\n",
    " - Stack Overflow\n",
    " - Others, see comments\n",
    "\n",
    "ver 0.02, in progress... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sets and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter lab\n",
    "# To get this working: https://github.com/matplotlib/jupyter-matplotlib\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebooks\n",
    "#%matplotlib notebook\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display_html\n",
    "from IPython.display import display\n",
    "\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    html_str = html_str.replace('table','table style=\"display:inline; border:0px\"')          \n",
    "    display_html(html_str,raw=True)\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotters for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_decision_boundaries(X, y, model, title = None):\n",
    "    '''\n",
    "    Takes as inputs \n",
    "        X_test (two features)\n",
    "        y_test\n",
    "        fitted model\n",
    "        \n",
    "    To do: Needs to be made dynamice w.r.t to target classes\n",
    "    '''\n",
    "    no_targets = len(y.unique())\n",
    "    \n",
    "    mesh_step_size = 0.01\n",
    "    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, mesh_step_size), np.arange(y_min, y_max, mesh_step_size))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Colors    \n",
    "    import matplotlib.colors as mcolors\n",
    "    colors = sns.color_palette(\"husl\", no_targets)\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"Custom\", colors, len(colors))\n",
    "    \n",
    "\n",
    "    # Figure\n",
    "    fig = plt.figure(figsize = (6,4), dpi = 100)\n",
    "    ax = fig.add_subplot(111)\n",
    "    scats = []\n",
    "    for i in range(no_targets):\n",
    "        ax.scatter(X[y.values == i,0], X[y.values == i,1], alpha = 0.8, label = i, color = colors[i], s = 10)\n",
    "    plt.imshow(Z, interpolation = 'nearest', cmap = cmap, alpha = 0.15,\n",
    "               extent=(x_min, x_max, y_min, y_max), origin = 'lower')\n",
    "    ax.legend()\n",
    "    #ax.set_aspect('equal')\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)    \n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_bin_decision_probs(X, y, model, title = None):\n",
    "    '''\n",
    "    Takes as inputs \n",
    "        X_test (two features)\n",
    "        y_test\n",
    "        fitted model\n",
    "    '''\n",
    "    no_targets = len(y.unique())\n",
    "    \n",
    "    mesh_step_size = 0.01\n",
    "    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, mesh_step_size), np.arange(y_min, y_max, mesh_step_size))\n",
    "    Z = model.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Colors    \n",
    "    #import matplotlib.colors as mcolors\n",
    "    #colors = sns.color_palette(\"husl\", no_targets)\n",
    "    #cmap = mcolors.LinearSegmentedColormap.from_list(\"Custom\", colors, 50)\n",
    "\n",
    "    # Figure\n",
    "    fig = plt.figure(figsize = (6,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    scats = []\n",
    "\n",
    "    ax.scatter(X[y.values == 0,0], X[y.values == 0,1], alpha = 0.8, label = '0', color = 'blue', s = 10)\n",
    "    ax.scatter(X[y.values == 1,0], X[y.values == 1,1], alpha = 0.8, label = '1', color = 'red', s = 10)\n",
    "\n",
    "    plt.imshow(Z, interpolation = 'nearest', cmap = 'RdYlBu_r', alpha = 0.15,\n",
    "               extent=(x_min, x_max, y_min, y_max), origin = 'lower')\n",
    "    ax.legend()\n",
    "    ax.set_aspect('equal')\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred, title):\n",
    "    \n",
    "    labelsno = len(np.unique(y_test))\n",
    "    df_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), index = [i for i in range(0,labelsno)],\n",
    "                  columns = [i for i in range(0,labelsno)])\n",
    "    \n",
    "    plt.figure(figsize = (6,4))\n",
    "    sns.heatmap(df_cm, annot=True)\n",
    "    plt.title(title + '\\nAccuracy: {0:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_bin_prcurve(precision, recall):\n",
    "    '''\n",
    "    y_test: test sample true labels\n",
    "    y_clf_score: scores from decision_function\n",
    "    closest_zero: clf_score closest to zero\n",
    "    '''\n",
    "    closest_zero = np.argmin(np.abs(thresholds))\n",
    "    closest_zero_p = precision[closest_zero]\n",
    "    closest_zero_r = recall[closest_zero]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim([0.0, 1.01])\n",
    "    ax.set_ylim([0.0, 1.01])    \n",
    "    ax.plot(precision, recall)\n",
    "    ax.plot(closest_zero_p, closest_zero_r, 'o', markersize = 12, fillstyle = 'none', c = 'r', mew = 3)\n",
    "    ax.set_xlabel('Precision')\n",
    "    ax.set_ylabel('Recall')    \n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_bin_ROC(y_test, y_pred):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    FPR, TPR, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(FPR, TPR)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim([-0.01, 1.00])\n",
    "    ax.set_ylim([-0.01, 1.00])    \n",
    "    ax.plot(FPR, TPR, lw = 3, label='ROC curve (area = {:0.3f})'.format(roc_auc))\n",
    "    ax.set_xlabel('FPR')\n",
    "    ax.set_ylabel('TPR')    \n",
    "    ax.set_title('ROC curve')\n",
    "    ax.legend(loc = 'lower right')\n",
    "    ax.plot([0, 1], [0, 1], color = 'navy', lw = 3, linestyle='--')\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_validation_curve(train_scores, validation_scores, param_range, param_name, scoring, title = 'Validation curve'):\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "    validation_scores_std = np.std(validation_scores, axis=1)    \n",
    "    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(param_name)\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_ylim(0.0, 1.1)\n",
    "    lw = 2\n",
    "    plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"darkorange\", lw=lw)\n",
    "    plt.fill_between( param_range, train_scores_mean - train_scores_std\n",
    "                     ,train_scores_mean + train_scores_std, alpha = 0.2\n",
    "                     ,color = 'darkorange', lw = lw)\n",
    "    plt.semilogx(param_range, validation_scores_mean, label=\"Cross-validation score\", color = 'navy', lw = lw)\n",
    "    plt.fill_between(param_range, validation_scores_mean - validation_scores_std,\n",
    "                     validation_scores_mean + validation_scores_std, alpha = 0.2,\n",
    "                     color = 'navy', lw = lw)\n",
    "    ax.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize iris data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ffbc91ad0a461ab0f35fc7eae88277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import math\n",
    "plt.close('all')\n",
    "\n",
    "X = iris.data[:, :2]  # for first plot only two first features \n",
    "y = iris.target\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "\n",
    "# Color map\n",
    "cmap = plt.cm.PuOr\n",
    "colors = []\n",
    "colors.append(cmap(0.3)); colors.append(cmap(0.6)); colors.append(cmap(0.9))\n",
    "cmap = cmap.from_list('Custom cmap', colors, 3)\n",
    "\n",
    "# Figure\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "\n",
    "# First axis\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.scatter(X[:, 0], X[:, 1], c = y, cmap = cmap, edgecolor = 'k')\n",
    "ax1.set_xlabel('Sepal length')\n",
    "ax1.set_ylabel('Sepal width')\n",
    "ax1.set_xlim(x_min, x_max)\n",
    "ax1.set_ylim(y_min, y_max)\n",
    "ax1.set_xticks(())\n",
    "ax1.set_yticks(())\n",
    "\n",
    "# legend\n",
    "patch1 = mpatches.Patch(color = cmap(0), label = iris.target_names[0])\n",
    "patch2 = mpatches.Patch(color = cmap(1), label = iris.target_names[1])\n",
    "patch3 = mpatches.Patch(color = cmap(2), label = iris.target_names[2])\n",
    "patches = [patch1, patch2, patch3]\n",
    "ax1.legend(handles = patches, loc='upper right')\n",
    "\n",
    "# To getter a better understanding of interaction of the dimensions\n",
    "# plot the first three PCA dimensions\n",
    "pca = PCA(n_components = 3)\n",
    "pca.fit(iris.data)\n",
    "X_reduced = pca.transform(iris.data)\n",
    "#X_reduced = PCA(n_components=3).fit_transform(iris.data)\n",
    "\n",
    "# Second axis\n",
    "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "ax2.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=y,\n",
    "           cmap=cmap, edgecolor='k', s=40)\n",
    "ax2.set_title(\"First three PCA directions\")\n",
    "ax2.set_xlabel(\"1st eigenvector\")\n",
    "ax2.w_xaxis.set_ticklabels([])\n",
    "ax2.set_ylabel(\"2nd eigenvector\")\n",
    "ax2.w_yaxis.set_ticklabels([])\n",
    "ax2.set_zlabel(\"3rd eigenvector\")\n",
    "ax2.w_zaxis.set_ticklabels([])\n",
    "ax2.view_init(azim = 110, elev = -150)\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb4ee0f01954f19a39d9d3030d0750d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_names = list(iris.feature_names)\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.imshow(pca.components_, interpolation = 'none', cmap = 'plasma')\n",
    "ax.grid(None)\n",
    "\n",
    "ax.set_xticks(np.arange(0, len(feature_names)))\n",
    "ax.set_yticks(np.arange(0, 3))\n",
    "ax.set_yticklabels(['First PC', 'Second PC', 'Third PC'], fontsize=12)\n",
    "ax.set_title(\"Heatmap for features' correlations with PCs\")\n",
    "\n",
    "ax.set_xticklabels(feature_names, rotation = 20, ha='right', fontsize = 10)\n",
    "plt.colorbar( ticks=[pca.components_.min(), 0, pca.components_.max()])\n",
    "#ax.set_xticklabels(feature_names, rotation = 60, ha='right', fontsize = 10)\n",
    "#plt.colorbar(orientation='horizontal', ticks=[pca.components_.min(), 0, pca.components_.max()], pad=0.65);\n",
    "\n",
    "plt.subplots_adjust(left= None, bottom = 0.2, right = None, top = None, wspace = None, hspace = None);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit learn bunch object into pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable iris is of type <class 'sklearn.datasets.base.Bunch'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Variable ''iris'' is of type ' + str(type(iris)))\n",
    "columns = list(iris.feature_names ) + ['target']\n",
    "iris_df = pd.DataFrame(np.concatenate((iris.data, np.array([iris.target]).T), axis=1), columns = columns)\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Full data\n",
    "y = iris_df['target']\n",
    "iris_df_temp = iris_df.copy(); del iris_df_temp['target']\n",
    "X = iris_df_temp\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = random_state)\n",
    "\n",
    "# For stratified version\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y, random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling and normalization\n",
    "See http://sebastianraschka.com/Articles/2014_about_feature_scaling.html\n",
    "\n",
    "Heurestic: the only family of algorithms that are truly scale-invariant are tree-based methods. Even in logistic regression feature scale might play a role if the optimization algorithm used is such that it converges more quickly with normalized data\n",
    "\n",
    "Essentially two alternatives:\n",
    " - Z-score standardization\n",
    " - minmax-scaling\n",
    "\n",
    "Which one to use? There's no obvious answer, it depends on the application. It seems that Z-score standardizations seems to be more common approach.\n",
    "\n",
    "Here we will have three sets: one unscaled, one z-score standardized, and one minmax-scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-score standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline; border:0px\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.701282</td>\n",
       "      <td>-0.850872</td>\n",
       "      <td>0.852239</td>\n",
       "      <td>0.902670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444603</td>\n",
       "      <td>-2.033225</td>\n",
       "      <td>0.390008</td>\n",
       "      <td>0.369166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline; border:0px\"><table style=\"display:inline; border:0px\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline; border:0px\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standardscaler = StandardScaler()\n",
    "standardscaler.fit(X_train)\n",
    "\n",
    "X_train_stand = standardscaler.transform(X_train)\n",
    "X_test_stand = standardscaler.transform(X_test)\n",
    "\n",
    "display_side_by_side(pd.DataFrame(X_train_stand).head(2), pd.DataFrame(X_train).head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMax scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline; border:0px\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline; border:0px\"><table style=\"display:inline; border:0px\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline; border:0px\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmaxscaler = MinMaxScaler()\n",
    "minmaxscaler.fit(X_train)\n",
    "\n",
    "X_train_mmscaled = minmaxscaler.transform(X_train)\n",
    "X_test_mmscaled = minmaxscaler.transform(X_test)\n",
    "\n",
    "display_side_by_side(pd.DataFrame(X_train_mmscaled).head(2), pd.DataFrame(X_train).head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data sets based on dimensionality reduction\n",
    "Based on the original and scaled/standardized datasets we will have following datasets:\n",
    "- Full, z-score standardized dataset: X_train/X_test\n",
    "- Reduced (only first two columns), minmax-scaled: X_train_mmscaled/X_test_mmscaled\n",
    "- Reduced (only first two columns), z-score standardized dataset: X_train_reduced/X_test_reduced\n",
    "- Reduced (first two PCs), z-score standardized dataset: X_train_pca/X_test_pca\n",
    "\n",
    "Dependent variable y data sets will just be called y_train and y_test as they will be the same no matter how the features are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline; border:0px\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.701282</td>\n",
       "      <td>-0.850872</td>\n",
       "      <td>0.852239</td>\n",
       "      <td>0.902670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444603</td>\n",
       "      <td>-2.033225</td>\n",
       "      <td>0.390008</td>\n",
       "      <td>0.369166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline; border:0px\"><table style=\"display:inline; border:0px\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.701282</td>\n",
       "      <td>-0.850872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444603</td>\n",
       "      <td>-2.033225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline; border:0px\"><table style=\"display:inline; border:0px\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.600457</td>\n",
       "      <td>0.435257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.219717</td>\n",
       "      <td>1.676353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline; border:0px\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Full data set\n",
    "X_train = X_train_stand\n",
    "X_test = X_test_stand\n",
    "\n",
    "# Reduced dimension data (2 dimensions, sepal width and length), minmax scaled\n",
    "X_train_mmscaled = X_train_mmscaled[:,[0,1]]\n",
    "X_test_mmscaled = X_test_mmscaled[:,[0,1]]\n",
    "\n",
    "# Reduced dimension data (2 dimensions, sepal width and length), standardized\n",
    "X_train_reduced = X_train_stand[:,[0,1]]\n",
    "X_test_reduced = X_test_stand[:,[0,1]]\n",
    "\n",
    "# Reduced dimension data (2 dimensions, first two principal components)\n",
    "model_pca = PCA(n_components=2).fit(X_train_stand)\n",
    "X_train_pca = model_pca.transform(X_train_stand)\n",
    "X_test_pca = model_pca.transform(X_test_stand)\n",
    "\n",
    "display_side_by_side(pd.DataFrame(X_train_stand).head(2),\n",
    "                     pd.DataFrame(X_train_reduced).head(2),                  \n",
    "                     pd.DataFrame(X_train_pca).head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target set where three classes have been reduced to binary case virginica vs. rest\n",
    "y_train_bin = pd.DataFrame(y_train).copy()\n",
    "y_test_bin = pd.DataFrame(y_test).copy()\n",
    "combined = [y_train_bin, y_test_bin]\n",
    "for dataset in combined:\n",
    "    dataset[dataset['target'] != 2] = 0\n",
    "    dataset[dataset['target'] == 2] = 1    \n",
    "y_train_bin = y_train_bin['target']\n",
    "y_test_bin = y_test_bin['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92efc18102ad405ab95e5d20d4a8c330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea42678ab4745b0b13a9ae39e1671bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "model_pca = LogisticRegression()\n",
    "model_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = model_pca.predict(X_test_pca)\n",
    "\n",
    "model_reduced = LogisticRegression()\n",
    "model_reduced.fit(X_train_reduced, y_train)\n",
    "y_pred_reduced = model_reduced.predict(X_test_reduced)\n",
    "\n",
    "# Plot decision boundaries\n",
    "plot_confusion_matrix(y_test,y_pred_pca, title = 'Conf matrix for log regression in PCA-reduced model')\n",
    "title = 'Logistic regression classifier'\n",
    "plot_decision_boundaries(X_test_pca, y_test, model_pca, title = title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8947368421052632\n",
      "0.7894736842105263\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_test, y_test))\n",
    "print(model_pca.score(X_test_pca, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest neighbours needs feature scaling. Since it relies on some distance measure between features, we need make sure that features are on comparable scale. Here we will use full minmac scaled feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc1a87de85243c685ef126ebe3111fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b7c31d9ac94dfcbcde48ffb83ec0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "n_neighbors = 3\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "model.fit(X_train_mmscaled,y_train)\n",
    "y_pred = model.predict(X_test_mmscaled)\n",
    "\n",
    "plot_confusion_matrix(y_test,y_pred, title = 'Conf matrix for KNN model')\n",
    "plot_decision_boundaries(X_test_mmscaled, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree\n",
    "The neat thing about decision trees is that they don't require any feature scaling. We can directly deploy non-scaled data.\n",
    "\n",
    "Petal length and width seem to be most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petal width (cm)</td>\n",
       "      <td>0.912910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>petal length (cm)</td>\n",
       "      <td>0.062510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sepal width (cm)</td>\n",
       "      <td>0.017876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sepal length (cm)</td>\n",
       "      <td>0.006703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature  Importance\n",
       "3   petal width (cm)    0.912910\n",
       "2  petal length (cm)    0.062510\n",
       "1   sepal width (cm)    0.017876\n",
       "0  sepal length (cm)    0.006703"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2154049eff49148947e67495d44e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32dbe5d660644becb7afdf3d3f26b5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pydotplus\n",
    "import io\n",
    "from scipy import misc\n",
    "\n",
    "\n",
    "def show_tree(decisionTree, file_path):\n",
    "    dotfile = io.StringIO()\n",
    "    tree.export_graphviz(decisionTree, out_file=dotfile)\n",
    "    pydotplus.graph_from_dot_data(dotfile.getvalue()).write_png(file_path)\n",
    "    i = misc.imread(file_path)\n",
    "    plt.imshow(i)\n",
    "    \n",
    "max_depth = 10 # None by default\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth = max_depth, random_state = 0)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "model_pca = DecisionTreeClassifier(max_depth = max_depth)\n",
    "model_pca.fit(X_train_pca,y_train)\n",
    "y_pred_pca = model_pca.predict(X_test_pca)\n",
    "\n",
    "# Most important features in full model\n",
    "res = pd.DataFrame(list(zip(X_train.columns, model.feature_importances_)))\n",
    "res.columns = ['Feature', 'Importance']\n",
    "res = res.sort_values(['Importance'], ascending  = False)\n",
    "display(res.head())\n",
    "\n",
    "# Write full model tree into .dot file for visualization\n",
    "# .dot file can be uploaded here http://www.webgraphviz.com/\n",
    "dotfile = open('dtree.dot', 'w')\n",
    "tree.export_graphviz(model, out_file = dotfile, feature_names = X_train.columns)\n",
    "dotfile.close()\n",
    "\n",
    "# cannot get graphviz to work...\n",
    "#show_tree(model, 'test.png')\n",
    "\n",
    "plot_confusion_matrix(y_test,y_pred_pca, title = 'Conf matrix for log regression in PCA-reduced model')\n",
    "plot_decision_boundaries(X_test_pca, y_test, model_pca, \n",
    "                         title = 'DT classifier with PCA-reduced data and max_depth = {}'.format(max_depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d8b88c7cf649d88b86d3b1fa61d4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18e7a7736d34930945b909849c0600a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "C = 5.0\n",
    "gamma = 'auto'\n",
    "kernel = 'rbf'\n",
    "\n",
    "model = SVC(kernel = kernel, C = C, gamma = gamma, random_state = 0)\n",
    "model.fit(X_train_mmscaled,y_train)\n",
    "y_pred = model.predict(X_test_mmscaled)\n",
    "\n",
    "plot_confusion_matrix(y_test,y_pred, title = 'Confusion matrix')\n",
    "plot_decision_boundaries(X_test_mmscaled, y_test, model, \n",
    "                         title = 'SVC with kernel = {}, C = {}, and gamma = {}'.format(kernel,C,gamma))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier\n",
    "\n",
    "Called \"naive\" since they make the assumption that features are conditionally independent, given the class. That is, for all instances in a given class, the features have no correlation with each other.\n",
    "\n",
    "Types:\n",
    " - Bernoulli: binary features\n",
    " - Multinomial: discrete features\n",
    " - Gaussian: continuous/real-valued features\n",
    " \n",
    "Gaussian NB is usually used with high-dimensional data. Bernoulli and multinomial NBs are typically used for text classification where there are very large number of distinct words as features and feature vectors are sparse. NBs are easy understand and can work as baseline against more sophisticated models. Downsides include the strong assumption about conditional independency, which can lead to inferior generalization performance and inaccurate confidence estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes rule:\n",
    "$$\n",
    "\\begin{align}\n",
    "& \\text{Posterior probability}  \\ = \\ \\frac{\\text{Prior probability}* \\text{Likelihood}}{\\text{Evidence}} \\\\[4pt]\n",
    "\\\n",
    "\\iff & Pr(y \\ | \\ X) = \\frac{Pr(y) * Pr(X \\ | \\ y)}{Pr(X)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Bayes rule based classification model:\n",
    "\n",
    "$$y^{*} = \\underset{y}{\\operatorname{argmax}} Pr(y \\ | \\ X) = \\underset{y}{\\operatorname{argmax}} Pr(y) \\ Pr(X \\ | \\ y)$$\n",
    "\n",
    "The \"naive\" assumption is that features $x_i$ are assumed to be independet of each other\n",
    "$$y^{*} = \\underset{y}{\\operatorname{argmax}} Pr(y) \\ Pr(X \\ | \\ y) = \\underset{y}{\\operatorname{argmax}} Pr(y) \\ \\prod_{i=1}^{n} Pr(x_i \\ | \\ y) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509f3301f4c44cb6a09bac0c938f3f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e151b48fb32e46de8bb2231bf596a435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We will use Gaussian Naive Bayes Classifier.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_mmscaled, y_train)\n",
    "y_pred = model.predict(X_test_mmscaled)\n",
    "\n",
    "plot_confusion_matrix(y_test,y_pred, title = 'Confusion matrix')\n",
    "plot_decision_boundaries(X_test_mmscaled, y_test, model, \n",
    "                         title = 'Gaussian Naive Bayes classifier')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forests\n",
    "Essentially, an ensemble of tress instead of one decision tree, providing more stable and better generalizable results.\n",
    "\n",
    "Original dataset $\\rightarrow$ <i>n_estimator</i> randomized bootstrapped data sets of the same size as the original data set $\\rightarrow$ randomized feature split, i.e. <i>n_estimator</i> trees $\\rightarrow$ ensemble prediction\n",
    "\n",
    "Same pros as decision trees, i.e. no need for careful feature scaling. In addition, might be more robust than single decision tree, easily parallelized across multiple CPUs. Cons: difficult for humans to interpret. However, it is noteworthy that aggregated/ensemble models are not universally better than their \"single\" counterparts, they are better if and only if the single models suffer of instability. For example here, on the PCA-reduced non-scaled feature data single decision tree performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ville_000\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571a13eba7274c47ba919045b25ee647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc428affd9548ad9bdb3698970e4016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = 10 # default = 10\n",
    "max_depth = 10 # Default = None\n",
    "criterion = 'gini' # default = gini, gini/entropy\n",
    "\n",
    "model_pca = RandomForestClassifier(n_estimators = n_estimators, criterion = criterion, random_state = 0)\n",
    "model_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = model_pca.predict(X_test_pca)\n",
    "\n",
    "plot_confusion_matrix(y_test,y_pred_pca, title = 'Confusion matrix for PCA-reduced model')\n",
    "plot_decision_boundaries(X_test_pca, y_test, model_pca, \n",
    "                         title = 'RF on PCA-reduced data with n_est = {}, max_depth = {} and criterion = {}'.format(n_estimators, max_depth, criterion))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosted decision trees\n",
    "\n",
    "Similar to RF in being an ensemle method, in GBDTs ensembling is done as a series of trees rather than building many trees in parallel as in RFs. Each consecutive tree is trained as to correct the mistakes of the previous tree in the series. Typically, GBDTs use \"weak learners\" (in this case shallow trees) build in non-stochastic way, to create a model that makes fewer and fewer mistakes down the line.\n",
    "\n",
    "Cons of GBDT include that it requires careful tuning of learning rate and other parameters. Further, like other tree models it is not well-suited for very high dimensional sparse features \n",
    "\n",
    "n_estimators and learning_rate are tuned togehter: n_estimators adjusted first to exploit memory and CPUs during training, then learning_rate. max_depth usually a small vlaue (e.g. 3-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed001db44149427b86825e8b8744ba2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96480bc26a0043658831fd15d8c6d520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "n_estimators = 100 # default = 100\n",
    "max_depth = 3 # default = 3\n",
    "criterion = 'friedman_mse' # default = friedman_mse, mae\n",
    "learning_rate = 0.1 # default = 0.1\n",
    "loss = 'deviance' # default = deviance, exponential\n",
    "\n",
    "model_pca = GradientBoostingClassifier(loss = loss, learning_rate = learning_rate, n_estimators = n_estimators, criterion = criterion, random_state = 0)\n",
    "model_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = model_pca.predict(X_test_pca)\n",
    "\n",
    "plot_confusion_matrix(y_test,y_pred_pca, title = 'Confusion matrix for PCA-reduced model')\n",
    "plot_decision_boundaries(X_test_pca, y_test, model_pca, \n",
    "                         title = 'GBDT on PCA-red data: n_est = {}, md = {},\\ncrit = {}, lrnrate = {}, loss = {}'\n",
    "                         .format(n_estimators, max_depth, criterion, learning_rate, loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple neural network (MLP)\n",
    "\n",
    "Multilayer perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2754d47bc9451fa207c9a4274d2429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1357850adf25476ab06655bfee0b2cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "solver ='lbfgs'\n",
    "layers = [100, 100]\n",
    "alpha = 5.0\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes = layers, alpha = alpha, random_state = 0, solver = solver)\n",
    "model.fit(X_train_mmscaled, y_train)\n",
    "y_pred = model.predict(X_test_mmscaled)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, title = 'Confusion matrix for PCA-reduced model')\n",
    "plot_decision_boundaries(X_test_mmscaled, y_test, model, \n",
    "                         title = 'MLP on PCA-red data: solver = {}, no_layers = {}, alpha = {}'\n",
    "                         .format(solver, len(layers), alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we learn about how to evaluate how good of a job out classifiaction model, or classifier, does. We also learn how to optimize the choice of classifier. Below is some general information about different evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit learn uses following confusion matrix build in binary classification:\n",
    "\n",
    "\\begin{bmatrix}\n",
    "    TN & FP \\\\\n",
    "    FN & TP\n",
    "\\end{bmatrix}\n",
    "\n",
    "<b><i>Accuracy</i></b> (Acc) is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "Acc = \\frac{TP + TN}{TN + TP + FN + FP}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "<b><i>Classification error</i></b> (CErr) is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "CErr = 1- Acc = \\frac{FP + FN}{TN + TP + FN + FP}\n",
    "\\end{equation}\n",
    "\n",
    "<b><i>Recall</i></b>, also known as TPR or sentivity, exhibits the probability of detection. It ranks higher if we not only have a high number of correct positive predictions (TPs) but also avoided missing true cases (avoided FNs). Example usage: crisis detection - it is very costly to miss a crisis. It is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "Recall = P(\\hat{Y} = 1 \\ | \\ Y = 1) = \\frac{TP}{TP + FN}\n",
    "\\end{equation}\n",
    "\n",
    "<b><i>Precision</i></b> exhibits what fraction of positive predictions are correct. This ranks higher when it is important to avoid wronly predicting a true case (avoiding FPs) and less important to have all true cases (TPs) detected. In other words, when the classifier predicts a positive class we want to be very confident that the prediction is correct. Example usage: query suggestion in a web search - it is very costy to falsely flag for a hit as customer will remember these. It is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "Precision = P(Y = 1 \\ | \\ \\hat{Y} = 1) = \\frac{TP}{TP + FP}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "<b><i>FPR</i></b>, also know as specifity, exhibits what fraction of all negative cases does the classifier incorrectly identify as positive. This metric ranks better (lower in FPR value) if we avoid falsely predicting positive cases (avoid FPs) and also manage correcly picking out negative cases (TNs). It is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "FPR = P(\\hat{Y} = 0 \\ | \\ Y = 0) = \\frac{FP}{TN + FP}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "<b>There is often a tradeoff between precision and recall</b>. We can define a measure called <b>F-score</b> that lets us determine the tradeoff between these two:\n",
    "\n",
    "\\begin{equation}\n",
    "F_{\\beta} = (1 + \\beta^2) \\  \\frac{Precision \\cdot Recall}{\\beta^2 \\cdot Precision + Recall}\n",
    "\\end{equation}\n",
    "\n",
    "To weight precision and recall equally: $\\beta = 1$<br>\n",
    "To weight precision over recall: $\\beta < 1$<br>\n",
    "To weight recall over precision: $\\beta > 1$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasons why classifier accuracy is close to null accuracy baseline from DummyClassifier:\n",
    "\n",
    "<ul style=\"list-style-type:circle\">\n",
    "  <li>Ineffective, missing, or erroneous features</li>\n",
    "  <li>Hyperparameters are poorly chose</li>\n",
    "  <li>Class imbalance</li>  \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One should use three data splits when running classification (or regression for that matter).\n",
    " - Training set, which is used for model building\n",
    " - Validation set, which is used for model selection/hyperparameter tuning\n",
    " - Test set, used for final evaluation\n",
    " \n",
    "In practice, one achieves this by doing the following:\n",
    " - Use train_test_split once for original data, to get the test set\n",
    " - Use train_test_split (or functions that do this automatically under the hood) again on the train data from previous step to split between training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select binary classifier to be used in this section\n",
    "We will use a Support Vector Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ffa3bc683e1437fb737f6ab8d2d6538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ville_000\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7baaf10f608548978d83c6d344f88eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae64395c45442e2b8fd9e05bc82b1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "C = 5.0\n",
    "gamma = 'auto'\n",
    "kernel = 'rbf'\n",
    "probability = True # If True, slows down SVC\n",
    "\n",
    "model = SVC(kernel = kernel, C = C, gamma = gamma, random_state = 0, probability = probability)\n",
    "model_untrained = SVC(kernel = kernel, C = C, gamma = 'auto', random_state = 0, probability = probability)\n",
    "model.fit(X_train_mmscaled,y_train_bin)\n",
    "y_pred = model.predict(X_test_mmscaled)\n",
    "\n",
    "title = 'SVC; kernel = {}, C = {}, and gamma = {}'.format(kernel,C,gamma)\n",
    "plot_confusion_matrix(y_test_bin ,y_pred, title = title)\n",
    "plot_decision_boundaries(X_test_mmscaled, y_test_bin, model, title = title)\n",
    "plot_bin_decision_probs(X_test_mmscaled, y_test_bin, model, title = title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For infor about difference between precision-recall curve and ROC curve, see https://stats.stackexchange.com/questions/7207/roc-vs-precision-and-recall-curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ville_000\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758e1a9f10794fa49814ff279695f8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_clf_score = model.decision_function(X_test_mmscaled)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_bin, y_clf_score)\n",
    "\n",
    "plot_bin_prcurve(precision, recall)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ville_000\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21b72ebed5d406d811a4fa5ca980c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_bin_ROC(y_test_bin, y_pred)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worthwhile to compare our classifier's performance against a dummy classifier, especially if the sample is imbalanced.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ville_000\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a146e7383994348abf4000a28a7b2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9c307ff57e42078d6d22eb7fe5b7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# most_frequent, stratified, uniform\n",
    "strategy = 'most_frequent'\n",
    "\n",
    "model_dummy = DummyClassifier(strategy = strategy)\n",
    "model_dummy.fit(X_train_mmscaled, y_train_bin)\n",
    "y_pred_dummy = model_dummy.predict(X_test_mmscaled)\n",
    "\n",
    "title = 'Dummy classifier using {}'.format(strategy)\n",
    "plot_confusion_matrix(y_test_bin ,y_pred_dummy, title = title)\n",
    "plot_decision_boundaries(X_test_mmscaled, y_test_bin, model_dummy, title = title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7826087  0.91304348 0.86956522 0.72727273 0.85714286]\n",
      "[0.81666667 0.975      0.9        0.85714286 0.84183673]\n",
      "[0.625      0.75       1.         0.5        0.57142857]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# accuracy, roc_auc, recall\n",
    "scoring = 'accuracy'\n",
    "folds = 5\n",
    "\n",
    "print(cross_val_score(model_untrained, X_train_mmscaled, y_train_bin, cv = folds, scoring = scoring))\n",
    "print(cross_val_score(model_untrained, X_train_mmscaled, y_train_bin, cv = folds, scoring = 'roc_auc'))\n",
    "print(cross_val_score(model_untrained, X_train_mmscaled, y_train_bin, cv = folds, scoring = 'recall'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gris search can be used in hyperparameter tuning. It is important to realize that optimal hyperparameter value might depend on according to which metric we are optimizing over. E.g. whether we are inclined more to recall or precision.\n",
    "\n",
    "GridSearchCV can be performed on initial training data split, as it will automatically perform a cross-validation of n folds on the input set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.scorer import SCORERS\n",
    "print(sorted(list(SCORERS.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search best parameter (accuracy): {'gamma': 10}\n",
      "Grid search best score (accuracy): 0.8125\n",
      "--------------------------------------------------\n",
      "Test set accuracy score:  0.7894736842105263\n",
      "Test set recall score:  0.8181818181818182\n",
      "Test set precision score:  0.6\n",
      "Test set AUC score:  0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "# Grid search for gamma parameter in SVC\n",
    "# This could be extended to multiple hyperparameters at the same time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, accuracy_score\n",
    "\n",
    "grid_values = {'gamma': [0.001, 0.01, 0.05, 0.1, 1, 10, 100]}\n",
    "scoring = 'accuracy' #accuracy, precision, recall, roc_auc\n",
    "ave_method = 'binary' #binary (default), micro, macro, samples, weighted\n",
    "\n",
    "grid_model = GridSearchCV(model_untrained, param_grid = grid_values, scoring = scoring)\n",
    "grid_model.fit(X_train_mmscaled, y_train_bin)\n",
    "y_grid_scores = grid_model.decision_function(X_test_mmscaled)\n",
    "y_grid_pred = grid_model.predict(X_test_mmscaled)\n",
    "\n",
    "print('Grid search best parameter ({}): {}'.format(scoring,grid_model.best_params_) )\n",
    "print('Grid search best score ({}): {}'.format(scoring, grid_model.best_score_))\n",
    "print('-'*50)\n",
    "\n",
    "print('Test set accuracy score: ', accuracy_score(y_test_bin, y_grid_pred))\n",
    "print('Test set recall score: ', recall_score(y_test_bin, y_grid_pred, average = ave_method))\n",
    "print('Test set precision score: ', precision_score(y_test_bin, y_grid_pred, average = ave_method))\n",
    "print('Test set AUC score: ', roc_auc_score(y_test_bin, y_grid_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html\n",
    "Compute scores for an estimator with different values of a specified parameter. This is similar to grid search with one parameter. However, this will also compute training scores and is merely a utility for plotting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ville_000\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f78c87ad1a840398df3bc0114259d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_name = 'gamma'\n",
    "scoring = 'accuracy'\n",
    "folds = 5\n",
    "param_range = [0.001, 0.01, 0.05, 0.1, 1, 10, 100]\n",
    "n_jobs = 1\n",
    "\n",
    "train_scores, validation_scores = validation_curve( model_untrained\n",
    "                                             ,X_train_mmscaled\n",
    "                                             ,y_train_bin\n",
    "                                             ,param_name = param_name\n",
    "                                             ,param_range = param_range\n",
    "                                             ,cv = folds\n",
    "                                             ,scoring = scoring\n",
    "                                             ,n_jobs = n_jobs\n",
    "                                            )\n",
    "\n",
    "title = 'Validation curve with method {}, folds = {}'.format(scoring, folds)\n",
    "plot_validation_curve(train_scores, validation_scores, param_range, param_name, scoring, title = title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lin_reg_plotter(coefs, X_train, X_test, y_test, poly_order, xlims, x_points = 20):\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    \n",
    "    x_ax0 = np.linspace(xlims[0], xlims[1], x_points).reshape(x_points, 1)\n",
    "    x_ax = PolynomialFeatures(poly_order).fit_transform(x_ax0)\n",
    "    y_ax = np.sum(x_ax * coefs, axis = 1).reshape(x_points, 1)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "    ax.scatter(X_test, y_test,  color = 'orange', label = 'test')\n",
    "    ax.scatter(X_train, y_train,  color = 'purple', label = 'train')        \n",
    "    ax.plot(x_ax0, y_ax, color='teal', linewidth = 3, label = 'poly = ' + str(poly_order))\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inspiration from https://gist.github.com/brentp/5355925\n",
    "# I would use stats rather than this...\n",
    "def p_values(lin_reg_model, X, y):\n",
    "        from scipy import stats\n",
    "        sse = np.sum((lin_reg_model.predict(X) - y) ** 2, axis=0) / float(X.shape[0] - X.shape[1])        \n",
    "        se = np.array([np.sqrt(np.diagonal(sse * np.linalg.inv(np.dot(X.T, X))))])\n",
    "        t = lin_reg_model.coef_ / se\n",
    "        p = 2 * (1 - stats.t.cdf(np.abs(t), y.shape[0] - X.shape[1]))\n",
    "        return p, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Paramters\n",
    "poly_order = 9\n",
    "grid_points = 100\n",
    "\n",
    "# Data\n",
    "np.random.seed(0)\n",
    "n = 15\n",
    "x = np.linspace(0, 10, n) + np.random.randn(n)/5\n",
    "y = np.sin(x) + x/6 + np.random.randn(n)/10\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 0)\n",
    "\n",
    "# Create polynomial features into train/test data if poly_order > 1\n",
    "X_train_pol = X_train.reshape(len(X_train),1)\n",
    "X_test_pol = X_test.reshape(len(X_test),1)\n",
    "polyfier = PolynomialFeatures(poly_order).fit(X_train_pol)\n",
    "X_train_pol = polyfier.transform(X_train_pol)\n",
    "X_test_pol = polyfier.transform(X_test_pol)\n",
    "\n",
    "# Linear regression model\n",
    "model_lin = LinearRegression(fit_intercept = False) # intercept included in features\n",
    "model_lin.fit(X_train_pol, y_train)\n",
    "y_pred_lin_test = model_lin.predict(X_test_pol)\n",
    "y_pred_lin_train = model_lin.predict(X_train_pol)\n",
    "print('R-squared for linear regression with poly_order = {} in train data is {:0.2f}'.format(poly_order, r2_score(y_train, y_pred_lin_train)))\n",
    "print('R-squared for linear regression with poly_order = {} in test data is {:0.2f}'.format(poly_order, r2_score(y_test, y_pred_lin_test)))\n",
    "print('-'*50)\n",
    "\n",
    "# Lasso regression model\n",
    "model_lasso = Lasso(alpha = 0.01, max_iter = 50000, fit_intercept = False) # intercept included in features\n",
    "model_lasso.fit(X_train_pol, y_train)\n",
    "y_pred_lasso_test = model_lasso.predict(X_test_pol)\n",
    "y_pred_lasso_train = model_lasso.predict(X_train_pol)\n",
    "print('R-squared for lasso regression with poly_order = {} in train data is {:0.2f}'.format(poly_order, r2_score(y_train, y_pred_lasso_train)))\n",
    "print('R-squared for lasso regression with poly_order = {} in test data is {:0.2f}'.format(poly_order, r2_score(y_test, y_pred_lasso_test)))\n",
    "print('-'*50)\n",
    "\n",
    "# Ridge regression model\n",
    "model_ridge = Ridge(alpha = 0.01, max_iter = 50000, fit_intercept = False) # intercept included in features\n",
    "model_ridge.fit(X_train_pol, y_train)\n",
    "y_pred_ridge_test = model_ridge.predict(X_test_pol)\n",
    "y_pred_ridge_train = model_ridge.predict(X_train_pol)\n",
    "print('R-squared for ridge regression with poly_order = {} in train data is {:0.2f}'.format(poly_order, r2_score(y_train, y_pred_ridge_train)))\n",
    "print('R-squared for ridge regression with poly_order = {} in test data is {:0.2f}'.format(poly_order, r2_score(y_test, y_pred_ridge_test)))\n",
    "\n",
    "#p_vals, _ = p_values(model, X_train_pol, y_train)\n",
    "#print('p-values are:' )\n",
    "#np.set_printoptions(precision = 3)\n",
    "#print(p_vals)\n",
    "\n",
    "lin_reg_plotter(model_lin.coef_, X_train, X_test, y_test, poly_order, [0,10], x_points = 100)\n",
    "lin_reg_plotter(model_lasso.coef_, X_train, X_test, y_test, poly_order, [0,10], x_points = 100)\n",
    "lin_reg_plotter(model_ridge.coef_, X_train, X_test, y_test, poly_order, [0,10], x_points = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "Inspired by https://www.kdnuggets.com/2017/12/managing-machine-learning-workflows-scikit-learn-pipelines-part-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train adn test data\n",
    "y = iris_df['target']\n",
    "iris_df_temp = iris_df.copy(); del iris_df_temp['target']\n",
    "X = iris_df_temp\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Psossible debuggin class to extract transformed training data\n",
    "# https://stackoverflow.com/questions/48743032/get-intermediate-data-state-in-scikit-learn-pipeline\n",
    "\n",
    "# Pipeline does not support transformations to your target \n",
    "# https://stackoverflow.com/questions/31259891/put-customized-functions-in-sklearn-pipeline\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class Debug(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Return X data\n",
    "        self.X = X\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline with stadard scaling of data, extracting first two PCAs, and logistic regression classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe_lr = Pipeline([\n",
    "                    ('scl', StandardScaler()),\n",
    "                    ('pca', PCA(n_components=2, random_state = random_state)),\n",
    "                    #(\"debug\", Debug()),\n",
    "                    ('clf', LogisticRegression(random_state=random_state))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train pipeline\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict using trained pipeline\n",
    "# Predict imposes same tranformations to the test set as have been used for train data in the pipeline\n",
    "# https://youtu.be/URdnFlZnlaE?t=479\n",
    "y_pred_pca = pipe_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know how to extract transformed X_test from pipe_lr.predict(X_test), so we cannot draw the decision regions like in the example without a pipeline. From confusion matrix and accuracy we see, however, that the results coincide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a681f0e8a48430494beece4e381e507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test,y_pred_pca, title = 'Conf matrix for log regression in PCA-reduced model')\n",
    "\n",
    "#title = 'Logistic regression classifier'\n",
    "#plot_decision_boundaries(X_test.values, y_test, model_lr, title = title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stuff to add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pipelines<br>\n",
    "Linear SVMs<br>\n",
    "Kernelized SVMs<br>\n",
    "\n",
    "\n",
    "Treating imbalanced datasets in classification<br>\n",
    "\n",
    "Different classification scoring metrics in action: classification_report. This especially for multi-class case, not just binary<br>\n",
    "Micro and macro averages in multi-class classification<br>\n",
    "\n",
    "Unsupervised learning: k-means clustering, manifold learning, agglomerative clustering, t-sne, dbscan \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {
    "height": "1020px",
    "left": "0px",
    "right": "1248.8px",
    "top": "107px",
    "width": "380px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
